{
  "benchmark_id": "mtvqa",
  "name": "MTVQA",
  "parent_benchmark_id": null,
  "categories": ["vision", "multimodal", "text-to-image"],
  "modality": "multimodal",
  "multilingual": true,
  "max_score": 1.0,
  "language": "en",
  "description": "MTVQA (Multilingual Text-Centric Visual Question Answering) is the first benchmark featuring high-quality human expert annotations across 9 diverse languages, consisting of 6,778 question-answer pairs across 2,116 images. It addresses visual-textual misalignment problems in multilingual text-centric VQA.",
  "paper_link": "https://arxiv.org/abs/2405.11985",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.587333+00:00",
  "updated_at": "2025-07-19T19:56:14.587333+00:00"
}