{
  "benchmark_id": "tau-bench",
  "name": "Tau-bench",
  "parent_benchmark_id": null,
  "categories": ["general", "reasoning"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "Ï„-bench: A benchmark for tool-agent-user interaction in real-world domains. Tests language agents' ability to interact with users and follow domain-specific rules through dynamic conversations using API tools and policy guidelines across retail and airline domains. Evaluates consistency and reliability of agent behavior over multiple trials.",
  "paper_link": "https://arxiv.org/abs/2406.12045",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:15.219001+00:00",
  "updated_at": "2025-07-19T19:56:15.219001+00:00"
}