{
  "benchmark_id": "swe-bench-verified-(multiple-attempts)",
  "name": "SWE-bench Verified (Multiple Attempts)",
  "parent_benchmark_id": null,
  "categories": ["reasoning"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "SWE-bench Verified is a human-validated subset of 500 test samples from the original SWE-bench dataset that evaluates AI systems' ability to automatically resolve real GitHub issues in Python repositories. Given a codebase and issue description, models must edit the code to successfully resolve the problem, requiring understanding and coordination of changes across multiple functions, classes, and files. The Verified version provides more reliable evaluation through manual validation of test samples.",
  "paper_link": "https://arxiv.org/abs/2310.06770",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:12.336780+00:00",
  "updated_at": "2025-07-19T19:56:12.336780+00:00"
}