{
  "benchmark_id": "mmvet",
  "name": "MMVet",
  "parent_benchmark_id": null,
  "categories": ["vision", "multimodal", "reasoning", "general", "spatial_reasoning", "math"],
  "modality": "multimodal",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "MM-Vet is an evaluation benchmark that examines large multimodal models on complicated multimodal tasks requiring integrated capabilities. It assesses six core vision-language capabilities: recognition, knowledge, spatial awareness, language generation, OCR, and math through questions that require one or more of these capabilities.",
  "paper_link": "https://arxiv.org/abs/2308.02490",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.684742+00:00",
  "updated_at": "2025-07-19T19:56:14.684742+00:00"
}