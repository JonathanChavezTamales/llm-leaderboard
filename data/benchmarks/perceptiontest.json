{
  "benchmark_id": "perceptiontest",
  "name": "PerceptionTest",
  "parent_benchmark_id": null,
  "categories": ["video", "multimodal", "reasoning", "physics", "spatial_reasoning"],
  "modality": "multimodal",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "A novel multimodal video benchmark designed to evaluate perception and reasoning skills of pre-trained models across video, audio, and text modalities. Contains 11.6k real-world videos (average 23 seconds) filmed by participants worldwide, densely annotated with six types of labels. Focuses on skills (Memory, Abstraction, Physics, Semantics) and reasoning types (descriptive, explanatory, predictive, counterfactual). Shows significant performance gap between human baseline (91.4%) and state-of-the-art video QA models (46.2%).",
  "paper_link": "https://arxiv.org/abs/2305.13786",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.708910+00:00",
  "updated_at": "2025-07-19T19:56:14.708910+00:00"
}