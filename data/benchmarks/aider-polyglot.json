{
  "benchmark_id": "aider-polyglot",
  "name": "Aider-Polyglot",
  "parent_benchmark_id": null,
  "categories": ["general", "code"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "A coding benchmark that evaluates LLMs on 225 challenging Exercism programming exercises across C++, Go, Java, JavaScript, Python, and Rust. Models receive two attempts to solve each problem, with test error feedback provided after the first attempt if it fails. The benchmark measures both initial problem-solving ability and capacity to edit code based on error feedback, providing an end-to-end evaluation of code generation and editing capabilities across multiple programming languages.",
  "paper_link": null,
  "implementation_link": "https://github.com/Aider-AI/polyglot-benchmark",
  "verified": false,
  "created_at": "2025-09-05T00:00:00.000000+00:00",
  "updated_at": "2025-09-30T00:00:00.000000+00:00"
}
