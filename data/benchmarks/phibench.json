{
  "benchmark_id": "phibench",
  "name": "PhiBench",
  "parent_benchmark_id": null,
  "categories": ["reasoning", "math", "general"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "PhiBench is an internal benchmark designed to evaluate diverse skills and reasoning abilities of language models, covering a wide range of tasks including coding (debugging, extending incomplete code, explaining code snippets) and mathematics (identifying proof errors, generating related problems). Created by Microsoft's research team to address limitations of standard academic benchmarks and guide the development of the Phi-4 model.",
  "paper_link": "https://arxiv.org/abs/2412.08905",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.121593+00:00",
  "updated_at": "2025-07-19T19:56:14.121593+00:00"
}