{
  "benchmark_id": "popqa",
  "name": "PopQA",
  "parent_benchmark_id": null,
  "categories": ["general", "reasoning"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "PopQA is an entity-centric open-domain question-answering dataset consisting of 14,000 QA pairs designed to evaluate language models' ability to memorize and recall factual knowledge across entities with varying popularity levels. The dataset probes both parametric memory (stored in model parameters) and non-parametric memory effectiveness, with questions covering 16 diverse relationship types from Wikidata converted to natural language using templates. Created by sampling knowledge triples from Wikidata and converting them to natural language questions, focusing on long-tail entities to understand LMs' strengths and limitations in memorizing factual knowledge.",
  "paper_link": "https://arxiv.org/abs/2212.10511",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:15.072897+00:00",
  "updated_at": "2025-07-19T19:56:15.072897+00:00"
}