{
  "benchmark_id": "browsecomp-zh",
  "name": "BrowseComp-zh",
  "parent_benchmark_id": "browsecomp",
  "categories": ["reasoning", "search"],
  "modality": "text",
  "multilingual": true,
  "max_score": 1.0,
  "language": "zh",
  "description": "A high-difficulty benchmark purpose-built to comprehensively evaluate LLM agents on the Chinese web, consisting of 289 multi-hop questions spanning 11 diverse domains including Film & TV, Technology, Medicine, and History. Questions are reverse-engineered from short, objective, and easily verifiable answers, requiring sophisticated reasoning and information reconciliation beyond basic retrieval. The benchmark addresses linguistic, infrastructural, and censorship-related complexities in Chinese web environments.",
  "paper_link": "https://arxiv.org/abs/2504.19314",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-09-15T00:00:00.000000+00:00",
  "updated_at": "2025-09-15T00:00:00.000000+00:00"
}
