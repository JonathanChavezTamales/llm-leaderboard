{
  "benchmark_id": "multi-if",
  "name": "Multi-IF",
  "parent_benchmark_id": null,
  "categories": ["reasoning", "communication", "language"],
  "modality": "text",
  "multilingual": true,
  "max_score": 1.0,
  "language": "en",
  "description": "Multi-IF benchmarks LLMs on multi-turn and multilingual instruction following. It expands upon IFEval by incorporating multi-turn sequences and translating English prompts into 7 other languages, resulting in 4,501 multilingual conversations with three turns each. The benchmark reveals that current leading LLMs struggle with maintaining accuracy in multi-turn instructions and shows higher error rates for non-Latin script languages.",
  "paper_link": "https://arxiv.org/abs/2410.15553",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.638787+00:00",
  "updated_at": "2025-07-19T19:56:14.638787+00:00"
}