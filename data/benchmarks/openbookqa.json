{
  "benchmark_id": "openbookqa",
  "name": "OpenBookQA",
  "parent_benchmark_id": null,
  "categories": ["reasoning", "general"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "OpenBookQA is a question-answering dataset modeled after open book exams for assessing human understanding. It contains 5,957 multiple-choice elementary-level science questions that probe understanding of 1,326 core science facts and their application to novel situations, requiring combination of open book facts with broad common knowledge through multi-hop reasoning.",
  "paper_link": "https://arxiv.org/abs/1809.02789",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.129348+00:00",
  "updated_at": "2025-07-19T19:56:14.129348+00:00"
}