{
  "benchmark_id": "meld",
  "name": "Meld",
  "parent_benchmark_id": null,
  "categories": ["multimodal", "psychology"],
  "modality": "multimodal",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "MELD (Multimodal EmotionLines Dataset) is a multimodal multi-party dataset for emotion recognition in conversations. Contains approximately 13,000 utterances from 1,433 dialogues extracted from the TV series Friends. Each utterance is annotated with emotion (Anger, Disgust, Sadness, Joy, Neutral, Surprise, Fear) and sentiment labels across audio, visual, and textual modalities.",
  "paper_link": "https://arxiv.org/abs/1810.02508",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.842977+00:00",
  "updated_at": "2025-07-19T19:56:14.842977+00:00"
}