{
  "benchmark_id": "bigcodebench-hard",
  "name": "BigCodeBench-Hard",
  "parent_benchmark_id": null,
  "categories": ["general", "reasoning"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "BigCodeBench-Hard is a subset of 148 challenging programming tasks from BigCodeBench, designed to evaluate large language models' ability to solve complex, real-world programming problems. These tasks require diverse function calls from multiple libraries across 7 domains including computation, networking, data analysis, and visualization. The benchmark tests compositional reasoning and the ability to implement complex instructions that span 139 libraries with an average of 2.8 libraries per task.",
  "paper_link": "https://arxiv.org/abs/2406.15877",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.512684+00:00",
  "updated_at": "2025-07-19T19:56:14.512684+00:00"
}