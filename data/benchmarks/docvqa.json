{
  "benchmark_id": "docvqa",
  "name": "DocVQA",
  "parent_benchmark_id": null,
  "categories": ["vision", "multimodal"],
  "modality": "multimodal",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "A dataset for Visual Question Answering on document images containing 50,000 questions defined on 12,000+ document images. The benchmark tests AI's ability to understand document structure and content, requiring models to comprehend document layout and perform information retrieval to answer questions about document images.",
  "paper_link": "https://arxiv.org/abs/2007.00398",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:12.825214+00:00",
  "updated_at": "2025-07-19T19:56:12.825214+00:00"
}