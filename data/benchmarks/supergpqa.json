{
  "benchmark_id": "supergpqa",
  "name": "SuperGPQA",
  "parent_benchmark_id": null,
  "categories": ["reasoning", "general", "math", "legal", "healthcare", "finance", "chemistry", "economics", "physics"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "SuperGPQA is a comprehensive benchmark that evaluates large language models across 285 graduate-level academic disciplines. The benchmark contains 25,957 questions covering 13 broad disciplinary areas including Engineering, Medicine, Science, and Law, with specialized fields in light industry, agriculture, and service-oriented domains. It employs a Human-LLM collaborative filtering mechanism with over 80 expert annotators to create challenging questions that assess graduate-level knowledge and reasoning capabilities.",
  "paper_link": "https://arxiv.org/abs/2502.14739",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-09-05T00:00:00.000000+00:00",
  "updated_at": "2025-09-05T00:00:00.000000+00:00"
}
