{
  "benchmark_id": "piqa",
  "name": "PIQA",
  "parent_benchmark_id": null,
  "categories": ["reasoning", "physics", "general"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "PIQA (Physical Interaction: Question Answering) is a benchmark dataset for physical commonsense reasoning in natural language. It tests AI systems' ability to answer questions requiring physical world knowledge through multiple choice questions with everyday situations, focusing on atypical solutions inspired by instructables.com. The dataset contains 21,000 multiple choice questions where models must choose the most appropriate solution for physical interactions.",
  "paper_link": "https://arxiv.org/abs/1911.11641",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:13.133817+00:00",
  "updated_at": "2025-07-19T19:56:13.133817+00:00"
}