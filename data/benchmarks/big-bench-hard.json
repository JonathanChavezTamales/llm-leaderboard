{
  "benchmark_id": "big-bench-hard",
  "name": "BIG-Bench Hard",
  "parent_benchmark_id": null,
  "categories": ["reasoning", "math", "language"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "BIG-Bench Hard (BBH) is a subset of 23 challenging BIG-Bench tasks selected because prior language model evaluations did not outperform average human-rater performance. The benchmark contains 6,511 evaluation examples testing various forms of multi-step reasoning including arithmetic, logical reasoning (Boolean expressions, logical deduction), geometric reasoning, temporal reasoning, and language understanding. Tasks require capabilities such as causal judgment, object counting, navigation, pattern recognition, and complex problem solving.",
  "paper_link": "https://arxiv.org/abs/2210.09261",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:13.222809+00:00",
  "updated_at": "2025-07-19T19:56:13.222809+00:00"
}