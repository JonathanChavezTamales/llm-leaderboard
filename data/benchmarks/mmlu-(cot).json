{
  "benchmark_id": "mmlu-(cot)",
  "name": "MMLU (CoT)",
  "parent_benchmark_id": null,
  "categories": ["language", "reasoning", "math", "general"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "Chain-of-Thought variant of the Massive Multitask Language Understanding benchmark, evaluating language models across 57 tasks including elementary mathematics, US history, computer science, law, and other professional and academic subjects. This version uses chain-of-thought prompting to elicit step-by-step reasoning.",
  "paper_link": "https://arxiv.org/abs/2009.03300",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.330830+00:00",
  "updated_at": "2025-07-19T19:56:14.330830+00:00"
}