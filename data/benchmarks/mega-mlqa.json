{
  "benchmark_id": "mega-mlqa",
  "name": "MEGA MLQA",
  "parent_benchmark_id": null,
  "categories": ["language", "reasoning"],
  "modality": "text",
  "multilingual": true,
  "max_score": 1.0,
  "language": "en",
  "description": "MLQA as part of the MEGA (Multilingual Evaluation of Generative AI) benchmark suite. A multi-way aligned extractive QA evaluation benchmark for cross-lingual question answering across 7 languages (English, Arabic, German, Spanish, Hindi, Vietnamese, and Simplified Chinese) with over 12K QA instances in English and 5K in each other language.",
  "paper_link": "https://arxiv.org/abs/2303.12528",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.187404+00:00",
  "updated_at": "2025-07-19T19:56:14.187404+00:00"
}