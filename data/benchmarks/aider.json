{
  "benchmark_id": "aider",
  "name": "Aider",
  "parent_benchmark_id": null,
  "categories": ["reasoning", "code"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "Aider is a comprehensive code editing benchmark based on 133 practice exercises from Exercism's Python repository, designed to evaluate AI models' ability to translate natural language coding requests into executable code that passes unit tests. The benchmark measures end-to-end code editing capabilities, including GPT's ability to edit existing code and format code changes for automated saving to local files. The Aider Polyglot variant extends this evaluation across 225 challenging exercises spanning C++, Go, Java, JavaScript, Python, and Rust, making it a standard benchmark for assessing multilingual code editing performance in AI research.",
  "paper_link": null,
  "implementation_link": "https://github.com/Aider-AI/aider",
  "verified": false,
  "created_at": "2025-07-19T19:56:14.566857+00:00",
  "updated_at": "2025-07-19T19:56:14.566857+00:00"
}
