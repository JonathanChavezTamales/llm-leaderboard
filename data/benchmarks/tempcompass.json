{
  "benchmark_id": "tempcompass",
  "name": "TempCompass",
  "parent_benchmark_id": null,
  "categories": ["vision", "multimodal", "reasoning"],
  "modality": "multimodal",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "TempCompass is a comprehensive benchmark for evaluating temporal perception capabilities of Video Large Language Models (Video LLMs). It constructs conflicting videos that share identical static content but differ in specific temporal aspects to prevent models from exploiting single-frame bias. The benchmark evaluates multiple temporal aspects including action, motion, speed, temporal order, and attribute changes across diverse task formats including multi-choice QA, yes/no QA, caption matching, and caption generation.",
  "paper_link": "https://arxiv.org/abs/2403.00476",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:14.748364+00:00",
  "updated_at": "2025-07-19T19:56:14.748364+00:00"
}