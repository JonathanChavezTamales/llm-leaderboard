{
  "benchmark_id": "ai2-reasoning-challenge-(arc)",
  "name": "AI2 Reasoning Challenge (ARC)",
  "parent_benchmark_id": null,
  "categories": ["reasoning", "general"],
  "modality": "text",
  "multilingual": false,
  "max_score": 1.0,
  "language": "en",
  "description": "A dataset of 7,787 genuine grade-school level, multiple-choice science questions assembled to encourage research in advanced question-answering. The dataset is partitioned into a Challenge Set and Easy Set, where the Challenge Set contains only questions answered incorrectly by both retrieval-based and word co-occurrence algorithms. Covers multiple scientific domains including biology, physics, earth science, and chemistry, requiring scientific reasoning, causal understanding, and conceptual knowledge beyond simple fact retrieval. Includes a supporting corpus of over 14 million science sentences.",
  "paper_link": "https://arxiv.org/abs/1803.05457",
  "implementation_link": "https://github.com/allenai/ARC-Solvers",
  "verified": false,
  "created_at": "2025-07-19T19:56:15.419158+00:00",
  "updated_at": "2025-07-19T19:56:15.419158+00:00"
}
