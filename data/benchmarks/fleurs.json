{
  "benchmark_id": "fleurs",
  "name": "FLEURS",
  "parent_benchmark_id": null,
  "categories": ["language", "speech-to-text"],
  "modality": "audio",
  "multilingual": true,
  "max_score": 100.0,
  "language": "en",
  "description": "Few-shot Learning Evaluation of Universal Representations of Speech - a parallel speech dataset in 102 languages built on FLoRes-101 with approximately 12 hours of speech supervision per language for tasks including ASR, speech language identification, translation and retrieval",
  "paper_link": "https://arxiv.org/abs/2205.12446",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:13.943695+00:00",
  "updated_at": "2025-07-19T19:56:13.943695+00:00"
}