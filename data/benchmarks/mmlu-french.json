{
  "benchmark_id": "mmlu-french",
  "name": "MMLU French",
  "parent_benchmark_id": null,
  "categories": ["language", "reasoning", "math", "general"],
  "modality": "text",
  "multilingual": true,
  "max_score": 1.0,
  "language": "fr",
  "description": "French language variant of the Massive Multitask Language Understanding benchmark, evaluating language models across 57 tasks including elementary mathematics, US history, computer science, law, and other professional and academic subjects. This multilingual version tests model performance in French.",
  "paper_link": "https://arxiv.org/abs/2009.03300",
  "implementation_link": null,
  "verified": false,
  "created_at": "2025-07-19T19:56:15.175211+00:00",
  "updated_at": "2025-07-19T19:56:15.175211+00:00"
}